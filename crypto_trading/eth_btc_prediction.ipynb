{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from scipy.ndimage.filters import maximum_filter1d, minimum_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_filter1d_valid(a, W):\n",
    "    hW = (W-1)//2 # Half window size\n",
    "    return maximum_filter1d(a,size=W, mode=\"constant\")[hW:-hW]\n",
    "\n",
    "def min_filter1d_valid(a, W):\n",
    "    hW = (W-1)//2 # Half window size\n",
    "    return minimum_filter1d(a,size=W)[hW:-hW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = '127.0.0.1'\n",
    "client = MongoClient(url, ssl=False)\n",
    "connection = client['binance_coins']\n",
    "coin = \"ETH\"\n",
    "symbol = \"{}BTC\".format(coin)\n",
    "coins_collection = connection[symbol]\n",
    "res = list(connection[symbol].find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 High\n",
      "1 Open\n",
      "2 Taker buy base asset volume\n",
      "3 Volume\n",
      "4 Open time\n",
      "5 Number of trades\n",
      "6 Low\n",
      "7 Quote asset volume\n",
      "8 Close\n",
      "9 Ignore\n",
      "10 Taker buy quote asset volume\n",
      "11 Close time\n",
      "(57921, 12)\n",
      "(28529, 12)\n",
      "(57921, 40)\n",
      "(28529, 40)\n"
     ]
    }
   ],
   "source": [
    "highs = []\n",
    "lows = []\n",
    "keys_list = res[0].keys()\n",
    "keys_list.remove('_id')\n",
    "x_data = []\n",
    "for r in res:\n",
    "    x = []\n",
    "    for k in keys_list:\n",
    "        x.append(r[k])\n",
    "    x_data.append(x)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "\n",
    "prediction_period_minutes = 24 * 60\n",
    "\n",
    "for i in range(len(keys_list)):\n",
    "    print i, keys_list[i]\n",
    "\n",
    "# x_max_data = max_filter1d_valid(x_data[:, 0], prediction_period_minutes)\n",
    "# x_min_data = min_filter1d_valid(x_data[:, 6], prediction_period_minutes)\n",
    "\n",
    "\n",
    "y_data = []\n",
    "for i in range(len(x_data)-40):\n",
    "    temp = []\n",
    "    for x in range(40):\n",
    "        temp.append(x_data[i+x][1])\n",
    "        \n",
    "    y_data.append(temp)\n",
    "\n",
    "y_data = np.array(y_data)\n",
    "x_data = x_data[:len(y_data)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=42)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "num_y_signals = y_train.shape[1]\n",
    "num_x_signals = X_train.shape[1]\n",
    "\n",
    "validation_data = (np.expand_dims(X_test, axis=0),\n",
    "                   np.expand_dims(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sequence_length = 1000\n",
    "\n",
    "def batch_generator(batch_size, sequence_length, X, Y):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        x_shape = (batch_size, sequence_length, X.shape[1])\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float32)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        y_shape = (batch_size, sequence_length, Y.shape[1])\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float32)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_samples - sequence_length)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            x_batch[i] = X[idx:idx+sequence_length]\n",
    "            y_batch[i] = Y[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length, X=X_train, Y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(units=512, return_sequences=True, input_shape=(None, num_x_signals,)))\n",
    "model.add(Dense(num_y_signals, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warmup_steps = 50\n",
    "\n",
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error between y_true and y_pred,\n",
    "    but ignore the beginning \"warmup\" part of the sequences.\n",
    "    \n",
    "    y_true is the desired output.\n",
    "    y_pred is the model's output.\n",
    "    \"\"\"\n",
    "\n",
    "    # The shape of both input tensors are:\n",
    "    # [batch_size, sequence_length, num_y_signals].\n",
    "\n",
    "    # Ignore the \"warmup\" parts of the sequences\n",
    "    # by taking slices of the tensors.\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "\n",
    "    # These sliced tensors both have this shape:\n",
    "    # [batch_size, sequence_length - warmup_steps, num_y_signals]\n",
    "\n",
    "    # Calculate the MSE loss for each value in these tensors.\n",
    "    # This outputs a 3-rank tensor of the same shape.\n",
    "    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n",
    "                                        predictions=y_pred_slice)\n",
    "\n",
    "    # Keras may reduce this across the first axis (the batch)\n",
    "    # but the semantics are unclear, so to be sure we use\n",
    "    # the loss across the entire tensor, we reduce it to a\n",
    "    # single scalar with the mean function.\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, None, 512)         806400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 40)          20520     \n",
      "=================================================================\n",
      "Total params: 826,920\n",
      "Trainable params: 826,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss_mse_warmup, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_checkpoint = '23_checkpoint.keras'\n",
    "\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "callback_tensorboard = TensorBoard(log_dir='./23_logs/', histogram_freq=0, write_graph=False)\n",
    "\n",
    "\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)\n",
    "\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
